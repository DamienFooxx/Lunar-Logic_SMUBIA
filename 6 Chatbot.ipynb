{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import streamlit as st\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "import logging\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrimeDataRAG:\n",
    "    def __init__(self):\n",
    "        # Initialize BERT sentence transformer for embeddings\n",
    "        self.embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Initialize a simpler pipeline for text generation\n",
    "        try:\n",
    "            self.generator = pipeline('text-generation', \n",
    "                                   model='gpt2',\n",
    "                                   max_length=200)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load text generation model: {e}\")\n",
    "            self.generator = None\n",
    "        \n",
    "        # Initialize vector store\n",
    "        self.vector_store = None\n",
    "        self.documents = []\n",
    "\n",
    "    def load_and_process_data(self, nodes_path: str, edges_path: str, patterns_path: str) -> None:\n",
    "        \"\"\"Load and process the crime network data\"\"\"\n",
    "        try:\n",
    "            # Load datasets\n",
    "            nodes_df = pd.read_csv(nodes_path)\n",
    "            edges_df = pd.read_csv(edges_path)\n",
    "            patterns_df = pd.read_csv(patterns_path)\n",
    "            \n",
    "            # Create text documents for each entity\n",
    "            for _, node in nodes_df.iterrows():\n",
    "                doc = self._create_entity_document(node, edges_df, patterns_df)\n",
    "                self.documents.append(doc)\n",
    "                \n",
    "            self._create_vector_store()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _create_entity_document(self, node: pd.Series, edges_df: pd.DataFrame, \n",
    "                              patterns_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Create a text document for a single entity\"\"\"\n",
    "        doc = [\n",
    "            f\"Entity: {node['Entity']}\",\n",
    "            f\"Type: {node['Type']}\",\n",
    "            f\"Number of Crimes: {node['NumCrimes']}\",\n",
    "            f\"Crimes: {node['Crimes']}\"\n",
    "        ]\n",
    "\n",
    "        # Add relationships\n",
    "        entity_edges = edges_df[\n",
    "            (edges_df['Source'] == node['Entity']) | \n",
    "            (edges_df['Target'] == node['Entity'])\n",
    "        ]\n",
    "        if not entity_edges.empty:\n",
    "            doc.append(\"\\nRelationships:\")\n",
    "            for _, edge in entity_edges.iterrows():\n",
    "                other_entity = edge['Target'] if edge['Source'] == node['Entity'] else edge['Source']\n",
    "                doc.append(f\"- Connected to {other_entity} through {edge['Relationship']} \"\n",
    "                         f\"(Crime: {edge['CrimeType']})\")\n",
    "\n",
    "        # Add patterns\n",
    "        entity_patterns = patterns_df[patterns_df['Entity'] == node['Entity']]\n",
    "        if not entity_patterns.empty:\n",
    "            doc.append(\"\\nCrime Patterns:\")\n",
    "            for _, pattern in entity_patterns.iterrows():\n",
    "                doc.append(f\"- Involved in {pattern['CrimeType']}\")\n",
    "\n",
    "        return \"\\n\".join(doc)\n",
    "\n",
    "    def _create_vector_store(self) -> None:\n",
    "        \"\"\"Initialize FAISS vector store with document embeddings\"\"\"\n",
    "        embeddings = self.embed_model.encode(self.documents)\n",
    "        dimension = embeddings.shape[1]\n",
    "        self.vector_store = faiss.IndexFlatL2(dimension)\n",
    "        self.vector_store.add(np.array(embeddings).astype('float32'))\n",
    "\n",
    "    def get_relevant_context(self, query: str, k: int = 3) -> List[str]:\n",
    "        \"\"\"Retrieve relevant documents for a query\"\"\"\n",
    "        query_embedding = self.embed_model.encode([query])\n",
    "        D, I = self.vector_store.search(\n",
    "            np.array(query_embedding).astype('float32'), k\n",
    "        )\n",
    "        return [self.documents[i] for i in I[0]]\n",
    "\n",
    "    def generate_response(self, query: str, context: List[str]) -> str:\n",
    "        \"\"\"Generate a response based on the query and retrieved context\"\"\"\n",
    "        if not self.generator:\n",
    "            return \"Text generation model not available. Using retrieval only.\\n\\n\" + \\\n",
    "                   \"\\n\".join(context)\n",
    "            \n",
    "        prompt = f\"Based on this crime network information:\\n{' '.join(context)}\\n\\n\" + \\\n",
    "                f\"Question: {query}\\n\\nAnswer:\"\n",
    "        \n",
    "        try:\n",
    "            response = self.generator(prompt, max_length=200)[0]['generated_text']\n",
    "            return response.split(\"Answer:\")[-1].strip()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating response: {e}\")\n",
    "            return \"Error generating response. Here is the relevant context:\\n\\n\" + \\\n",
    "                   \"\\n\".join(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_streamlit_app():\n",
    "    st.title(\"Crime Network Analysis Chatbot\")\n",
    "    \n",
    "    @st.cache_resource\n",
    "    def load_rag_system():\n",
    "        try:\n",
    "            rag = CrimeDataRAG()\n",
    "            rag.load_and_process_data(\n",
    "                \"/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/Tablaeu Data/crime_network_clean_nodes.csv\",\n",
    "                \"/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/Tablaeu Data/crime_network_clean_edges.csv\",\n",
    "                \"/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/Tablaeu Data/crime_network_clean_patterns.csv\",\n",
    "                \"/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/Tablaeu Data/entity_risk_scores.csv\",\n",
    "                \"/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/Tablaeu Data/feature_importance.csv\",\n",
    "                \"/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/process2_cleaned.csv\",\n",
    "                \"/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/process3_crime_relationships_enhanced.csv\"\n",
    "            )\n",
    "            return rag\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error initializing system: {e}\")\n",
    "            return None\n",
    "\n",
    "    rag = load_rag_system()\n",
    "    \n",
    "    if not rag:\n",
    "        st.error(\"Failed to initialize the system. Please check the logs.\")\n",
    "        return\n",
    "\n",
    "    query = st.text_input(\"Ask a question about the crime network:\")\n",
    "    \n",
    "    if query:\n",
    "        try:\n",
    "            with st.spinner(\"Searching relevant information...\"):\n",
    "                context = rag.get_relevant_context(query)\n",
    "            \n",
    "            with st.spinner(\"Generating response...\"):\n",
    "                response = rag.generate_response(query, context)\n",
    "                \n",
    "            st.write(\"Response:\", response)\n",
    "            \n",
    "            with st.expander(\"View Source Context\"):\n",
    "                for i, doc in enumerate(context, 1):\n",
    "                    st.text(f\"Document {i}:\\n{doc}\\n\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error processing query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 16:55:55.607 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:55:55.608 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:55:55.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:55:55.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:55:55.610 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-02-01 16:55:56.114 Thread 'Thread-20': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:55:56.115 Thread 'Thread-20': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "Device set to use mps:0\n",
      "2025-02-01 16:56:12.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:56:12.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:56:12.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:56:12.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:56:12.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-01 16:56:12.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    create_streamlit_app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freshsmubia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
