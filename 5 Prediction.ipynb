{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from scipy.stats import zscore\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepeatOffenderPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.model = None\n",
    "        self.feature_importance = None\n",
    "        \n",
    "    def load_data(self, nodes_path, edges_path, patterns_path):\n",
    "        \"\"\"Load and merge network data\"\"\"\n",
    "        self.nodes_df = pd.read_csv(nodes_path)\n",
    "        self.edges_df = pd.read_csv(edges_path)\n",
    "        self.patterns_df = pd.read_csv(patterns_path)\n",
    "        \n",
    "        # Create graph for network metrics\n",
    "        self.G = nx.from_pandas_edgelist(self.edges_df, 'Source', 'Target')\n",
    "    \n",
    "    def engineer_features(self):\n",
    "        \"\"\"Create features for prediction\"\"\"\n",
    "        features = pd.DataFrame()\n",
    "        features['Entity'] = self.nodes_df['Entity']\n",
    "        \n",
    "        # Basic metrics from nodes\n",
    "        features['Degree'] = self.nodes_df['Degree']\n",
    "        features['NumCrimes'] = self.nodes_df['NumCrimes']\n",
    "        features['DegreeCentrality'] = self.nodes_df['DegreeCentrality']\n",
    "        features['BetweennessCentrality'] = self.nodes_df['BetweennessCentrality']\n",
    "        \n",
    "        # Network metrics\n",
    "        features['PageRank'] = pd.Series(nx.pagerank(self.G))\n",
    "        features['ClusteringCoeff'] = pd.Series(nx.clustering(self.G))\n",
    "        \n",
    "        # Crime type encoding\n",
    "        crime_dummies = self.patterns_df.pivot_table(\n",
    "            index='Entity', \n",
    "            columns='CrimeType',\n",
    "            values='Centrality',\n",
    "            aggfunc='count',\n",
    "            fill_value=0\n",
    "        )\n",
    "        features = features.join(crime_dummies, on='Entity')\n",
    "        \n",
    "        # Connection patterns\n",
    "        entity_connections = self.edges_df.groupby('Source')['Target'].count()\n",
    "        features['ConnectionCount'] = features['Entity'].map(entity_connections).fillna(0)\n",
    "        \n",
    "        # Evidence strength patterns\n",
    "        evidence_counts = self.edges_df.groupby('Source')['EvidenceStrength'].value_counts().unstack(fill_value=0)\n",
    "        features = features.join(evidence_counts, on='Entity')\n",
    "        \n",
    "        # Define repeat offender (target variable)\n",
    "        features['IsRepeatOffender'] = (features['NumCrimes'] > 1).astype(int)\n",
    "        \n",
    "        self.features = features.fillna(0)\n",
    "        return self.features\n",
    "    \n",
    "    def prepare_model_data(self):\n",
    "        \"\"\"Prepare data for modeling\"\"\"\n",
    "        # Separate features and target\n",
    "        X = self.features.drop(['Entity', 'IsRepeatOffender'], axis=1)\n",
    "        y = self.features['IsRepeatOffender']\n",
    "        \n",
    "        # Split data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"Train XGBoost classifier\"\"\"\n",
    "        self.model = xgb.XGBClassifier(\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            n_estimators=100,\n",
    "            objective='binary:logistic',\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Store feature importance\n",
    "        self.feature_importance = pd.DataFrame({\n",
    "            'feature': self.X_train.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        report = classification_report(self.y_test, y_pred, output_dict=True)\n",
    "        conf_matrix = confusion_matrix(self.y_test, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'feature_importance': self.feature_importance\n",
    "        }\n",
    "    \n",
    "    def generate_risk_scores(self):\n",
    "        \"\"\"Generate risk scores for all entities\"\"\"\n",
    "        # Get probability predictions\n",
    "        X = self.features.drop(['Entity', 'IsRepeatOffender'], axis=1)\n",
    "        probabilities = self.model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Create risk scores dataframe\n",
    "        risk_scores = pd.DataFrame({\n",
    "            'Entity': self.features['Entity'],\n",
    "            'RiskScore': probabilities\n",
    "        })\n",
    "        \n",
    "        # Assign risk levels using percentile ranges to handle duplicates\n",
    "        risk_scores['RiskPercentile'] = risk_scores['RiskScore'].rank(pct=True)\n",
    "        risk_scores['RiskLevel'] = pd.cut(\n",
    "            risk_scores['RiskPercentile'],\n",
    "            bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "            labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'],\n",
    "            include_lowest=True\n",
    "        )\n",
    "        \n",
    "        return risk_scores.sort_values('RiskScore', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Complete:\n",
      "Number of features: 22\n",
      "\n",
      "Model Training Complete\n",
      "\n",
      "Model Evaluation:\n",
      "Classification Report:\n",
      "              precision  recall  f1-score  support\n",
      "0                   1.0     1.0       1.0     84.0\n",
      "1                   1.0     1.0       1.0      9.0\n",
      "accuracy            1.0     1.0       1.0      1.0\n",
      "macro avg           1.0     1.0       1.0     93.0\n",
      "weighted avg        1.0     1.0       1.0     93.0\n",
      "\n",
      "Top 10 Highest Risk Entities:\n",
      "             Entity  RiskScore  RiskPercentile  RiskLevel\n",
      "425        Un-Sacco   0.981855        0.948052  Very High\n",
      "413           Airpo   0.981855        0.948052  Very High\n",
      "433          Unicef   0.981855        0.948052  Very High\n",
      "44               Un   0.981855        0.948052  Very High\n",
      "431  Unicef/Somalia   0.981855        0.948052  Very High\n",
      "310        Septembe   0.981855        0.948052  Very High\n",
      "313        Procurem   0.981855        0.948052  Very High\n",
      "426      Ed Nations   0.981855        0.948052  Very High\n",
      "424           Sacco   0.981855        0.948052  Very High\n",
      "423              Su   0.981855        0.948052  Very High\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize predictor\n",
    "    predictor = RepeatOffenderPredictor()\n",
    "    \n",
    "    # Load data\n",
    "    predictor.load_data(\n",
    "        '/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/Tablaeu Data/crime_network_clean_nodes.csv',\n",
    "        '/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/Tablaeu Data/crime_network_clean_edges.csv',\n",
    "        '/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/Tablaeu Data/crime_network_clean_patterns.csv'\n",
    "    )\n",
    "    \n",
    "    # Engineer features\n",
    "    features = predictor.engineer_features()\n",
    "    print(\"\\nFeature Engineering Complete:\")\n",
    "    print(f\"Number of features: {features.shape[1]}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test = predictor.prepare_model_data()\n",
    "    \n",
    "    # Train model\n",
    "    model = predictor.train_model()\n",
    "    print(\"\\nModel Training Complete\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluation = predictor.evaluate_model()\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(pd.DataFrame(evaluation['classification_report']).T)\n",
    "    \n",
    "    # Generate risk scores\n",
    "    risk_scores = predictor.generate_risk_scores()\n",
    "    print(\"\\nTop 10 Highest Risk Entities:\")\n",
    "    print(risk_scores.head(10))\n",
    "    \n",
    "    # Save outputs\n",
    "    risk_scores.to_csv('/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/entity_risk_scores.csv', index=False)\n",
    "    predictor.feature_importance.to_csv('/Users/damienfoo/Desktop/SMUBIA Datathon Lunar Logic/FINAL FINAL PLEASE/Data/feature_importance.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freshsmubia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
